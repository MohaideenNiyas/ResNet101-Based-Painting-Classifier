{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata loaded successfully!\n",
      "Number of unique classes: 1211\n",
      "Epoch 1/50\n",
      "88/88 [==============================] - 35s 87ms/step - loss: 10.7455 - accuracy: 0.0014 - val_loss: 9.6785 - val_accuracy: 0.0028\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 7s 80ms/step - loss: 8.8189 - accuracy: 0.0229 - val_loss: 8.7800 - val_accuracy: 0.0085\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 7s 81ms/step - loss: 7.8066 - accuracy: 0.0793 - val_loss: 8.2783 - val_accuracy: 0.0341\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 7.0669 - accuracy: 0.1222 - val_loss: 8.0818 - val_accuracy: 0.0227\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 6.4884 - accuracy: 0.1751 - val_loss: 7.9690 - val_accuracy: 0.0341\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 5.9062 - accuracy: 0.2330 - val_loss: 8.1787 - val_accuracy: 0.0398\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 5.3315 - accuracy: 0.3452 - val_loss: 7.9903 - val_accuracy: 0.0511\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 4.8523 - accuracy: 0.4132 - val_loss: 8.3114 - val_accuracy: 0.0568\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 4.3717 - accuracy: 0.4775 - val_loss: 8.1898 - val_accuracy: 0.0455\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 3.8861 - accuracy: 0.5625 - val_loss: 8.6740 - val_accuracy: 0.0511\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 3.3815 - accuracy: 0.6555 - val_loss: 8.6191 - val_accuracy: 0.0597\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 2.9603 - accuracy: 0.6919 - val_loss: 9.6019 - val_accuracy: 0.0028\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 7s 84ms/step - loss: 2.6386 - accuracy: 0.7241 - val_loss: 8.2712 - val_accuracy: 0.0682\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 2.3355 - accuracy: 0.7677 - val_loss: 8.9952 - val_accuracy: 0.0767\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 2.1715 - accuracy: 0.7784 - val_loss: 9.0380 - val_accuracy: 0.0852\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.9795 - accuracy: 0.7949 - val_loss: 9.1601 - val_accuracy: 0.0824\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.8349 - accuracy: 0.8041 - val_loss: 9.7428 - val_accuracy: 0.0653\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.7252 - accuracy: 0.8091 - val_loss: 9.8220 - val_accuracy: 0.0682\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.7019 - accuracy: 0.8170 - val_loss: 9.8864 - val_accuracy: 0.0852\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.5237 - accuracy: 0.8499 - val_loss: 9.8472 - val_accuracy: 0.0824\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.4963 - accuracy: 0.8456 - val_loss: 11.5754 - val_accuracy: 0.0341\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.4735 - accuracy: 0.8513 - val_loss: 9.5783 - val_accuracy: 0.0852\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 8s 87ms/step - loss: 1.4206 - accuracy: 0.8477 - val_loss: 9.9289 - val_accuracy: 0.0994\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.3862 - accuracy: 0.8413 - val_loss: 10.2952 - val_accuracy: 0.0994\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 7s 84ms/step - loss: 1.3511 - accuracy: 0.8542 - val_loss: 9.9961 - val_accuracy: 0.0767\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.2792 - accuracy: 0.8635 - val_loss: 9.8662 - val_accuracy: 0.0994\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.3250 - accuracy: 0.8420 - val_loss: 10.5919 - val_accuracy: 0.0710\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 7s 84ms/step - loss: 1.3454 - accuracy: 0.8363 - val_loss: 10.6896 - val_accuracy: 0.0881\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.3053 - accuracy: 0.8377 - val_loss: 10.7225 - val_accuracy: 0.0739\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.3089 - accuracy: 0.8399 - val_loss: 10.6855 - val_accuracy: 0.1193\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 7s 84ms/step - loss: 1.2553 - accuracy: 0.8599 - val_loss: 10.8793 - val_accuracy: 0.0909\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 7s 84ms/step - loss: 1.3132 - accuracy: 0.8349 - val_loss: 11.3665 - val_accuracy: 0.0881\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 7s 84ms/step - loss: 1.3506 - accuracy: 0.8184 - val_loss: 10.7863 - val_accuracy: 0.0966\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.3233 - accuracy: 0.8327 - val_loss: 11.0051 - val_accuracy: 0.0909\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.4022 - accuracy: 0.8299 - val_loss: 10.9298 - val_accuracy: 0.0824\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 7s 84ms/step - loss: 1.4267 - accuracy: 0.8299 - val_loss: 11.5364 - val_accuracy: 0.0653\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.3245 - accuracy: 0.8377 - val_loss: 11.1085 - val_accuracy: 0.0994\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.2906 - accuracy: 0.8585 - val_loss: 10.9733 - val_accuracy: 0.0824\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 7s 84ms/step - loss: 1.2721 - accuracy: 0.8385 - val_loss: 11.5481 - val_accuracy: 0.0994\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.3035 - accuracy: 0.8420 - val_loss: 11.0944 - val_accuracy: 0.1193\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 7s 85ms/step - loss: 1.3371 - accuracy: 0.8184 - val_loss: 11.2311 - val_accuracy: 0.0852\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 8s 85ms/step - loss: 1.3541 - accuracy: 0.8292 - val_loss: 12.6790 - val_accuracy: 0.0710\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 7s 84ms/step - loss: 1.3873 - accuracy: 0.8177 - val_loss: 12.9627 - val_accuracy: 0.0653\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 7s 84ms/step - loss: 1.3058 - accuracy: 0.8449 - val_loss: 11.8773 - val_accuracy: 0.0966\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 7s 84ms/step - loss: 1.2554 - accuracy: 0.8585 - val_loss: 16.2640 - val_accuracy: 0.0398\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 7s 84ms/step - loss: 1.3358 - accuracy: 0.8342 - val_loss: 12.4307 - val_accuracy: 0.0852\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.3375 - accuracy: 0.8420 - val_loss: 15.8916 - val_accuracy: 0.0369\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 7s 84ms/step - loss: 1.4125 - accuracy: 0.8192 - val_loss: 12.7579 - val_accuracy: 0.0682\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 7s 84ms/step - loss: 1.3173 - accuracy: 0.8406 - val_loss: 12.5374 - val_accuracy: 0.0881\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.3872 - accuracy: 0.8077 - val_loss: 11.8187 - val_accuracy: 0.0824\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 12s 95ms/step - loss: 1.5436 - accuracy: 0.7777 - val_loss: 11.2433 - val_accuracy: 0.1165\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 7s 84ms/step - loss: 1.3679 - accuracy: 0.8170 - val_loss: 11.2383 - val_accuracy: 0.1250\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 8s 85ms/step - loss: 1.2569 - accuracy: 0.8530 - val_loss: 11.2624 - val_accuracy: 0.1222\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.2333 - accuracy: 0.8649 - val_loss: 11.3635 - val_accuracy: 0.1307\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 7s 84ms/step - loss: 1.2005 - accuracy: 0.8728 - val_loss: 11.3188 - val_accuracy: 0.1307\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.2037 - accuracy: 0.8678 - val_loss: 11.3905 - val_accuracy: 0.1364\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 8s 88ms/step - loss: 1.1748 - accuracy: 0.8742 - val_loss: 11.4594 - val_accuracy: 0.1392\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 8s 85ms/step - loss: 1.1143 - accuracy: 0.9064 - val_loss: 11.5090 - val_accuracy: 0.1392\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 8s 85ms/step - loss: 1.0932 - accuracy: 0.8985 - val_loss: 11.4956 - val_accuracy: 0.1392\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 8s 85ms/step - loss: 1.0901 - accuracy: 0.9021 - val_loss: 11.6188 - val_accuracy: 0.1364\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 8s 86ms/step - loss: 1.0385 - accuracy: 0.9149 - val_loss: 11.6906 - val_accuracy: 0.1335\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 8s 86ms/step - loss: 1.0503 - accuracy: 0.9207 - val_loss: 11.6933 - val_accuracy: 0.1420\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 8s 87ms/step - loss: 1.0208 - accuracy: 0.9278 - val_loss: 11.6657 - val_accuracy: 0.1335\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 8s 86ms/step - loss: 1.0176 - accuracy: 0.9257 - val_loss: 11.6883 - val_accuracy: 0.1307\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 8s 85ms/step - loss: 1.0301 - accuracy: 0.9171 - val_loss: 11.6843 - val_accuracy: 0.1335\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 8s 88ms/step - loss: 0.9909 - accuracy: 0.9342 - val_loss: 11.7789 - val_accuracy: 0.1307\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 8s 87ms/step - loss: 0.9880 - accuracy: 0.9350 - val_loss: 11.7407 - val_accuracy: 0.1307\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 8s 87ms/step - loss: 0.9718 - accuracy: 0.9328 - val_loss: 11.7799 - val_accuracy: 0.1307\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 8s 88ms/step - loss: 0.9693 - accuracy: 0.9278 - val_loss: 11.8069 - val_accuracy: 0.1335\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 8s 85ms/step - loss: 0.9438 - accuracy: 0.9442 - val_loss: 11.8106 - val_accuracy: 0.1335\n",
      "Model and label encoder saved!\n",
      "Error loading image E:/dl2/dataset/munch_paintings/86.jpg: [Errno 2] No such file or directory: 'E:\\\\dl2\\\\dataset\\\\munch_paintings\\\\86.jpg'\n",
      "Invalid image!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
    "from tensorflow.keras.applications import ResNet101  # Import ResNet101\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "dataset_path = r\"E:\\Niyas\\dataset\"  # Replace with your dataset path\n",
    "metadata_file = os.path.join(dataset_path, \"edvard_munch.csv\")\n",
    "image_dir = os.path.join(dataset_path, \"munch_paintings\")\n",
    "image_size = (224, 224)  # Larger input size\n",
    "batch_size = 16\n",
    "initial_epochs = 50\n",
    "fine_tune_epochs = 20\n",
    "initial_learning_rate = 1e-3\n",
    "fine_tune_learning_rate = 1e-5\n",
    "\n",
    "# Load metadata\n",
    "if os.path.exists(metadata_file):\n",
    "    metadata = pd.read_csv(metadata_file)\n",
    "    print(\"Metadata loaded successfully!\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"Metadata file not found!\")\n",
    "\n",
    "# Filter and clean metadata\n",
    "required_columns = [\"name\", \"year\", \"location\", \"status\", \"technique\", \"filename\"]\n",
    "metadata = metadata[required_columns].dropna(subset=[\"filename\"])\n",
    "metadata[\"filename\"] = metadata[\"filename\"].astype(str).str.strip()\n",
    "metadata[\"image_path\"] = metadata[\"filename\"].apply(lambda x: os.path.join(image_dir, x))\n",
    "metadata = metadata[metadata[\"image_path\"].apply(os.path.exists)]\n",
    "\n",
    "if metadata.empty:\n",
    "    raise ValueError(\"No valid images found in metadata!\")\n",
    "\n",
    "# Load and preprocess images\n",
    "def load_and_preprocess_image(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"RGB\").resize(image_size)\n",
    "        img_array = np.array(img, dtype=np.float32)\n",
    "        return tf.keras.applications.resnet.preprocess_input(img_array)  # Preprocess for ResNet\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "for _, row in metadata.iterrows():\n",
    "    image = load_and_preprocess_image(row[\"image_path\"])\n",
    "    if image is not None:\n",
    "        images.append(image)\n",
    "        labels.append(row[\"name\"])  # Use 'name' column as the label\n",
    "\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"Number of unique classes: {num_classes}\")\n",
    "y_one_hot = to_categorical(labels_encoded, num_classes=num_classes)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define data augmentation\n",
    "train_data_gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")\n",
    "\n",
    "val_data_gen = ImageDataGenerator()  # Validation data will not be augmented\n",
    "\n",
    "train_gen = train_data_gen.flow(X_train, y_train, batch_size=batch_size)\n",
    "val_gen = val_data_gen.flow(X_test, y_test, batch_size=batch_size)\n",
    "\n",
    "# Define model using ResNet50\n",
    "base_model = ResNet101(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))  # Use ResNet101\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(256, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Freeze base model layers for initial training\n",
    "base_model.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=initial_learning_rate),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Compute class weights\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(labels_encoded),\n",
    "    y=labels_encoded\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=len(X_train) // batch_size,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=len(X_test) // batch_size,\n",
    "    epochs=initial_epochs,\n",
    "    class_weight=class_weights  # Apply class weights\n",
    ")\n",
    "\n",
    "# Fine-tuning: Unfreeze some layers of the base model\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-30]:  # Freeze earlier layers\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile with a smaller learning rate\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=fine_tune_learning_rate),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "history_fine = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=len(X_train) // batch_size,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=len(X_test) // batch_size,\n",
    "    epochs=fine_tune_epochs,\n",
    "    class_weight=class_weights\n",
    ")\n",
    "\n",
    "# Save the model and label encoder\n",
    "model.save(\"painting_recognition_model_resnet50_finetuned_1.h5\")\n",
    "np.save(\"label_classes_resnet50_1.npy\", label_encoder.classes_)\n",
    "print(\"Model and label encoder saved!\")\n",
    "\n",
    "# Prediction Function\n",
    "def predict_image(image_path):\n",
    "    image = load_and_preprocess_image(image_path)\n",
    "    if image is None:\n",
    "        print(\"Invalid image!\")\n",
    "        return\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    predictions = model.predict(image)\n",
    "    predicted_class_idx = np.argmax(predictions)\n",
    "    predicted_class = label_encoder.inverse_transform([predicted_class_idx])[0]\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "    print(\"Image Information:\")\n",
    "    print(metadata[metadata[\"name\"] == predicted_class])\n",
    "\n",
    "# Test prediction\n",
    "test_image_path = r\"E:/Niyas/dataset/munch_paintings/86.jpg\"  # Replace with the path to a test image\n",
    "predict_image(test_image_path)\n",
    "\n",
    "\n",
    "#  Define model using ResNet101\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata loaded successfully!\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Predicted Class: Telthusbakken with Gamle Aker Church\n",
      "Image Information:\n",
      "                                   name  year          location status  \\\n",
      "0  Telthusbakken with Gamle Aker Church  1880  Location unknown    NaN   \n",
      "\n",
      "      technique filename                              image_path  \n",
      "0   carton, oil    1.jpg  E:\\Niyas\\dataset\\munch_paintings\\1.jpg  \n",
      "Telthusbakken with Gamle Aker Church by Edvard Munch\n",
      "Title: File:Edvard Munch - Telthusbakken with Gamle Aker Church (1880 ...\n",
      "URL: https://commons.wikimedia.org/wiki/File:Edvard_Munch_-_Telthusbakken_with_Gamle_Aker_Church_(1880).jpg\n",
      "Snippet: Jun 12, 2024 ... This is a faithful photographic reproduction of a two-dimensional, public domain work of art. The work of art itself is in the public domain.\n",
      "\n",
      "Title: Edvard Munch Telthusbakken with Gamle Aker ... - Amazon.com\n",
      "URL: https://www.amazon.com/Telthusbakken-Painting-Picture-Unframed-12x18inch/dp/B0C3MWYY11\n",
      "Snippet: Amazon.com: Edvard Munch Telthusbakken with Gamle Aker Church Art Print Wall Art Poster Scroll Canvas Painting Picture Living Room Decor Home ...\n",
      "\n",
      "Title: Object - Munchmuseet\n",
      "URL: https://www.munchmuseet.no/en/object/MM.T.00121-13\n",
      "Snippet: Title, Telthusbakken med Gamle Aker kirke (NO) Telthusbakken with Gamle Aker Church (EN). Painter, Edvard Munch, Norwegian. Date, 1882.\n",
      "\n",
      "Title: Gamle Aker Church by Edvard Munch | USEUM\n",
      "URL: https://useum.org/artwork/Gamle-Aker-Church-Edvard-Munch-1881-1\n",
      "Snippet: painting by Edvard Munch (1881 - 2) (Museum: Munch Museum)\n",
      "\n",
      "Title: Old Aker Church - Wikipedia\n",
      "URL: https://en.wikipedia.org/wiki/Old_Aker_Church\n",
      "Snippet: 84226. Telthusbakken with Gamle Aker kirke. Edvard Munch (1880). Contents. 1 History; 2 Old Aker Cemetery. 2.1 Notable interments. 3 Gallery; 4 References; 5 ...\n",
      "\n",
      "Title: Oslo Wall Art | Canvas Art, Art Prints & Framed Canvas\n",
      "URL: https://www.elephantstock.com/collections/oslo-wall-art\n",
      "Snippet: Canvas ArtEdvard Munch · 1 piece Telthusbakken With Gamle Aker Church Wall Art on a living room wall. With. 0. Telthusbakken With Gamle Aker Church. Find ...\n",
      "\n",
      "Title: List of paintings by Edvard Munch - Wikipedia\n",
      "URL: https://en.wikipedia.org/wiki/List_of_paintings_by_Edvard_Munch\n",
      "Snippet: Telthusbakken with Gamle Aker Church, 1880, Location unknown. 2, Øvre Foss, 1880, Munch Museum, Oslo, Norway. 3, Small Lake with Boat, 1880, Munch Museum, Oslo, ...\n",
      "\n",
      "Title: Alternative Oslo: Exploring the Quiet Corners of Norway's Capital ...\n",
      "URL: https://galloparoundtheglobe.com/exploring-the-quiet-corners-of-oslo-alternative-oslo-sights-and-attractions/\n",
      "Snippet: Jan 17, 2019 ... ... Telthusbakken – one of several attractions we had on our itinerary for that morning. ... Gamle Aker Kirke (Old Aker Church). This is also where ...\n",
      "\n",
      "Title: Edvard Munch(1863-1944) - Telthusbakken With Gamle Aker Church\n",
      "URL: https://www.artunlimitedshop.co.uk/a17237-telthusbakken-with-gamle-aker-church-postcard.html\n",
      "Snippet: Edvard Munch(1863-1944) - Telthusbakken With Gamle Aker Church - Card for sale at Art Unlimited - The largest postcard collection (more than 20.000) ...\n",
      "\n",
      "Title: Old aker church hi-res stock photography and images - Alamy\n",
      "URL: https://www.alamy.com/stock-photo/old-aker-church.html\n",
      "Snippet: Edvard Munch Telthusbakken with Gamle Aker Church (1880) Stock Photohttps://www.alamy ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the API key\n",
    "api_key = os.getenv(\"API_KEY\")\n",
    "\n",
    "model = load_model(\"painting_recognition_model_resnet50_finetuned_1.h5\")\n",
    "label_classes = np.load(\"label_classes_resnet50_1.npy\", allow_pickle=True)\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.classes_ = label_classes\n",
    "image_size = (224, 224)\n",
    "dataset_path = r\"E:\\Niyas\\dataset\"  # Replace with your dataset path\n",
    "metadata_file = os.path.join(dataset_path, \"edvard_munch.csv\")\n",
    "image_dir = os.path.join(dataset_path, \"munch_paintings\")\n",
    "\n",
    "if os.path.exists(metadata_file):\n",
    "    metadata = pd.read_csv(metadata_file)\n",
    "    print(\"Metadata loaded successfully!\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"Metadata file not found!\")\n",
    "\n",
    "# Filter and clean metadata\n",
    "required_columns = [\"name\", \"year\", \"location\", \"status\", \"technique\", \"filename\"]\n",
    "metadata = metadata[required_columns].dropna(subset=[\"filename\"])\n",
    "metadata[\"filename\"] = metadata[\"filename\"].astype(str).str.strip()\n",
    "metadata[\"image_path\"] = metadata[\"filename\"].apply(lambda x: os.path.join(image_dir, x))\n",
    "metadata = metadata[metadata[\"image_path\"].apply(os.path.exists)]\n",
    "\n",
    "if metadata.empty:\n",
    "    raise ValueError(\"No valid images found in metadata!\")\n",
    "\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"RGB\").resize(image_size)\n",
    "        img_array = np.array(img, dtype=np.float32)\n",
    "        return tf.keras.applications.resnet.preprocess_input(img_array)  # Preprocess for ResNet\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def predict_image(image_path):\n",
    "    image = load_and_preprocess_image(image_path)\n",
    "    if image is None:\n",
    "        print(\"Invalid image!\")\n",
    "        return\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    predictions = model.predict(image)\n",
    "    predicted_class_idx = np.argmax(predictions)\n",
    "    predicted_class = label_encoder.inverse_transform([predicted_class_idx])[0]\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "    print(\"Image Information:\")\n",
    "    print(metadata[metadata[\"name\"] == predicted_class])\n",
    "    \n",
    "    search_query = predicted_class+\" by Edvard Munch\"\n",
    "    print(search_query)\n",
    "    results = fetch_google_search_results(search_query,api_key, cx='20b79b15ec0d844c2')\n",
    "    for result in results:\n",
    "        print(f\"Title: {result['title']}\")\n",
    "        print(f\"URL: {result['link']}\")\n",
    "        print(f\"Snippet: {result['snippet']}\\n\")\n",
    "    # result = fetch_wikipedia_summary(predicted_class)\n",
    "    # if result:\n",
    "    #     print(f\"Title: {result['title']}\")\n",
    "    #     print(f\"Description: {result['description']}\")\n",
    "    #     print(f\"URL: {result['url']}\")\n",
    "\n",
    "import requests\n",
    "from urllib.parse import quote\n",
    "\n",
    "# def fetch_wikipedia_summary(topic):\n",
    "#     \"\"\"\n",
    "#     Fetch a summary of the given topic from Wikipedia.\n",
    "    \n",
    "#     Args:\n",
    "#         topic (str): The topic to search for on Wikipedia.\n",
    "    \n",
    "#     Returns:\n",
    "#         dict: A dictionary with the title, description, and URL of the page.\n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         # Format the topic for the API (replace spaces with underscores)\n",
    "#         formatted_topic = topic.replace(\" \", \"_\")\n",
    "#         url = f\"https://en.wikipedia.org/api/rest_v1/page/summary/{formatted_topic}\"\n",
    "        \n",
    "#         # Make the request\n",
    "#         response = requests.get(url)\n",
    "#         response.raise_for_status()  # Raise an HTTPError for bad responses (4xx, 5xx)\n",
    "        \n",
    "#         # Parse the JSON response\n",
    "#         data = response.json()\n",
    "#         return {\n",
    "#             \"title\": data.get(\"title\", \"N/A\"),\n",
    "#             \"description\": data.get(\"extract\", \"No description available.\"),\n",
    "#             \"url\": data.get(\"content_urls\", {}).get(\"desktop\", {}).get(\"page\", \"N/A\")\n",
    "#         }\n",
    "#     except requests.exceptions.RequestException as e:\n",
    "#         print(f\"Error fetching Wikipedia summary: {e}\")\n",
    "#         return None\n",
    "import requests\n",
    "from urllib.parse import quote\n",
    "\n",
    "def fetch_google_search_results(query, api_key, cx):\n",
    "    \"\"\"\n",
    "    Fetches search results from Google Custom Search API.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query to search on Google.\n",
    "        api_key (str): Your Google API key.\n",
    "        cx (str): Your Custom Search Engine ID (CX).\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of dictionaries containing search result information.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # URL encode the query\n",
    "        encoded_query = quote(query)\n",
    "        \n",
    "        # Construct the API request URL\n",
    "        search_url = f\"https://www.googleapis.com/customsearch/v1?q={encoded_query}&key={api_key}&cx={cx}\"\n",
    "        \n",
    "        # Make the request\n",
    "        response = requests.get(search_url)\n",
    "        response.raise_for_status()  # Raise an HTTPError for bad responses (4xx, 5xx)\n",
    "        \n",
    "        # Parse the JSON response\n",
    "        search_data = response.json()\n",
    "        \n",
    "        # Extract relevant information from search results\n",
    "        search_results = []\n",
    "        for item in search_data.get(\"items\", []):\n",
    "            result = {\n",
    "                \"title\": item[\"title\"],\n",
    "                \"link\": item[\"link\"],\n",
    "                \"snippet\": item[\"snippet\"]\n",
    "            }\n",
    "            search_results.append(result)\n",
    "        \n",
    "        return search_results\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching search results: {e}\")\n",
    "        return []\n",
    "\n",
    "# Usage example\n",
    "# api_key = 'YOUR_GOOGLE_API_KEY'  # Replace with your Google API key\n",
    "# cx = 'YOUR_CUSTOM_SEARCH_ENGINE_ID'  # Replace with your Custom Search Engine ID\n",
    "\n",
    "# Query for the artwork by Edvard Munch\n",
    "\n",
    "\n",
    "\n",
    "# Print search results\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# Test prediction\n",
    "test_image_path = r\"E:/Niyas/dataset/munch_paintings/1.jpg\"  # Replace with the path to a test image\n",
    "predict_image(test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install python-dotenv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
